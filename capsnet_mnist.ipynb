{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import math, os\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Overarching Model\n",
    "'''\n",
    "class CapsNet(nn.Module):\n",
    "    def __init__(self, routing_iterations, n_classes=10):\n",
    "        super(CapsNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 256, kernel_size=9, stride=1)\n",
    "        \n",
    "        self.primaryCaps = PrimaryCapsLayer(256, 32, 8, kernel_size=9, stride=2)  # outputs: normalized sheets\n",
    "        \n",
    "        self.num_primaryCaps = 32 * 6 * 6\n",
    "        routing_module = AgreementRouting(self.num_primaryCaps, n_classes, routing_iterations)\n",
    "        self.digitCaps = CapsLayer(self.num_primaryCaps, 8, n_classes, 16, routing_module)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = F.relu(x)\n",
    "        x = self.primaryCaps(x) # output sheet\n",
    "        x = self.digitCaps(x) # output score matrix (before final flat)\n",
    "        probs = x.pow(2).sum(dim=2).sqrt()\n",
    "        return x, probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input: FM after 1st convolution\n",
    "Output: Normalized sheet\n",
    "'''\n",
    "class PrimaryCapsLayer(nn.Module):\n",
    "    def __init__(self, input_channels, output_caps, output_dim, kernel_size, stride):\n",
    "        super(PrimaryCapsLayer, self).__init__()\n",
    "        self.conv = nn.Conv2d(input_channels, output_caps * output_dim, kernel_size=kernel_size, stride=stride)\n",
    "        self.input_channels = input_channels\n",
    "        self.output_caps = output_caps\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv(input)\n",
    "        N, C, H, W = out.size()\n",
    "        out = out.view(N, self.output_caps, self.output_dim, H, W) # splitting into capsules\n",
    "\n",
    "        # will output N x OUT_CAPS x OUT_DIM\n",
    "        out = out.permute(0, 1, 3, 4, 2).contiguous() \n",
    "        out = out.view(out.size(0), -1, out.size(4)) # flat N*sheet\n",
    "        out = squash(out) # normalize\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(x):\n",
    "    lengths2 = x.pow(2).sum(dim=2)\n",
    "    lengths = lengths2.sqrt()\n",
    "    x = x * (lengths2 / (1 + lengths2) / lengths).view(x.size(0), x.size(1), 1)\n",
    "    return x\n",
    "\n",
    "\n",
    "class AgreementRouting(nn.Module):\n",
    "    def __init__(self, input_caps, output_caps, n_iterations):\n",
    "        super(AgreementRouting, self).__init__()\n",
    "        self.n_iterations = n_iterations\n",
    "        self.b = nn.Parameter(torch.zeros((input_caps, output_caps)))\n",
    "\n",
    "    def forward(self, u_predict):\n",
    "        batch_size, input_caps, output_caps, output_dim = u_predict.size()\n",
    "        \n",
    "        c = F.softmax(self.b)\n",
    "        s = (c.unsqueeze(2) * u_predict).sum(dim=1)\n",
    "        v = squash(s)\n",
    "\n",
    "        if self.n_iterations > 0:\n",
    "            b_batch = self.b.expand((batch_size, input_caps, output_caps))\n",
    "            for r in range(self.n_iterations):\n",
    "                v = v.unsqueeze(1)\n",
    "                b_batch = b_batch + (u_predict * v).sum(-1)\n",
    "\n",
    "                c = F.softmax(b_batch.view(-1, output_caps)).view(-1, input_caps, output_caps, 1)\n",
    "                s = (c * u_predict).sum(dim=1)\n",
    "                v = squash(s)\n",
    "\n",
    "        return v\n",
    "\n",
    "\n",
    "class CapsLayer(nn.Module):\n",
    "    def __init__(self, input_caps, input_dim, output_caps, output_dim, routing_module):\n",
    "        super(CapsLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.input_caps = input_caps\n",
    "        self.output_dim = output_dim\n",
    "        self.output_caps = output_caps\n",
    "        self.weights = nn.Parameter(torch.Tensor(input_caps, input_dim, output_caps * output_dim))\n",
    "        self.routing_module = routing_module\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.input_caps)\n",
    "        self.weights.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, caps_output):\n",
    "        caps_output = caps_output.unsqueeze(2)\n",
    "        u_predict = caps_output.matmul(self.weights)\n",
    "        u_predict = u_predict.view(u_predict.size(0), self.input_caps, self.output_caps, self.output_dim)\n",
    "        v = self.routing_module(u_predict)\n",
    "        return v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reconstruction Stuff \n",
    "class ReconstructionNet(nn.Module):\n",
    "    def __init__(self, n_dim=16, n_classes=10):\n",
    "        super(ReconstructionNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_dim * n_classes, 512)\n",
    "        self.fc2 = nn.Linear(512, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 784)\n",
    "        self.n_dim = n_dim\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        mask = Variable(torch.zeros((x.size()[0], self.n_classes)), requires_grad=False)\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            mask = mask.cuda()\n",
    "        mask.scatter_(1, target.view(-1, 1), 1.)\n",
    "        mask = mask.unsqueeze(2)\n",
    "        x = x * mask\n",
    "        x = x.view(-1, self.n_dim * self.n_classes)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class CapsNetWithReconstruction(nn.Module):\n",
    "    def __init__(self, capsnet, reconstruction_net):\n",
    "        super(CapsNetWithReconstruction, self).__init__()\n",
    "        self.capsnet = capsnet\n",
    "        self.reconstruction_net = reconstruction_net\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        x, probs = self.capsnet(x)\n",
    "        reconstruction = self.reconstruction_net(x, target)\n",
    "        return reconstruction, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Loss Functions\n",
    "class MarginLoss(nn.Module):\n",
    "    def __init__(self, m_pos, m_neg, lambda_):\n",
    "        super(MarginLoss, self).__init__()\n",
    "        self.m_pos = m_pos\n",
    "        self.m_neg = m_neg\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def forward(self, lengths, targets, size_average=True):\n",
    "        t = torch.zeros(lengths.size()).long()\n",
    "        if targets.is_cuda:\n",
    "            t = t.cuda()\n",
    "        t = t.scatter_(1, targets.data.view(-1, 1), 1)\n",
    "        targets = Variable(t)\n",
    "        losses = targets.float() * F.relu(self.m_pos - lengths).pow(2) + \\\n",
    "                 self.lambda_ * (1. - targets.float()) * F.relu(lengths - self.m_neg).pow(2)\n",
    "        return losses.mean() if size_average else losses.sum()\n",
    "\n",
    "### save model\n",
    "def saveModel(model,name,state_dict=False):\n",
    "    if state_dict:\n",
    "        torch.save(model.state_dict(),name)\n",
    "    else:\n",
    "        torch.save(model,name)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Epoch,Loss,Rec_loss_every=1):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target, requires_grad=False)\n",
    "        optimizer.zero_grad()\n",
    "        if RECONSTRUCTION:\n",
    "            output, probs = model(data, target)\n",
    "            reconstruction_loss = F.mse_loss(output, data.view(-1, 784))\n",
    "            margin_loss = loss_fn(probs, target)\n",
    "            loss = reconstruction_alpha * reconstruction_loss + margin_loss\n",
    "        else:\n",
    "            output, probs = model(data)\n",
    "            loss = loss_fn(probs, target)\n",
    "        \n",
    "        if batch_idx % Rec_loss_every == 0:\n",
    "            Loss.append(loss.data[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % LOG_INT == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                Epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "\n",
    "        if RECONSTRUCTION:\n",
    "            output, probs = model(data, target)\n",
    "            reconstruction_loss = F.mse_loss(output, data.view(-1, 784), size_average=False).data[0]\n",
    "            test_loss += loss_fn(probs, target, size_average=False).data[0]\n",
    "            test_loss += reconstruction_alpha * reconstruction_loss\n",
    "        else:\n",
    "            output, probs = model(data)\n",
    "            test_loss += loss_fn(probs, target, size_average=False).data[0]\n",
    "\n",
    "        pred = probs.data.max(1, keepdim=True)[1]  # get the index of the max probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining paramters, loaders, SGD elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training settings\n",
    "# parser = argparse.ArgumentParser(description='CapsNet with MNIST')\n",
    "# parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "#                     help='input batch size for training (default: 64)')\n",
    "# parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "#                     help='input batch size for testing (default: 1000)')\n",
    "# parser.add_argument('--epochs', type=int, default=250, metavar='N',\n",
    "#                     help='number of epochs to train (default: 10)')\n",
    "# parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
    "#                     help='learning rate (default: 0.01)')\n",
    "# parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "#                     help='disables CUDA training')\n",
    "# parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "#                     help='random seed (default: 1)')\n",
    "# parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "#                     help='how many batches to wait before logging training status')\n",
    "# parser.add_argument('--routing_iterations', type=int, default=3)\n",
    "# parser.add_argument('--with_reconstruction', action='store_true', default=False)\n",
    "# args = parser.parse_args()\n",
    "# args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "TEST_BATCH_SIZE = 1000\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "CUDA = torch.cuda.is_available()\n",
    "SEED = 1\n",
    "LOG_INT = 10 # how many batches to wait before logging training status\n",
    "ROUTING_ITERS = 3\n",
    "RECONSTRUCTION = False\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Pad(2), transforms.RandomCrop(28),\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])),\n",
    "    batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = CapsNet(ROUTING_ITERS)\n",
    "\n",
    "if RECONSTRUCTION:\n",
    "    reconstruction_model = ReconstructionNet(16, 10)\n",
    "    reconstruction_alpha = 0.0005\n",
    "    model = CapsNetWithReconstruction(model, reconstruction_model)\n",
    "\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=5, min_lr=1e-6)\n",
    "loss_fn = MarginLoss(0.9, 0.1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.080883\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.056401\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.037683\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.033561\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.022048\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.015681\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.014932\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.012336\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.009352\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.008090\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.009220\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.007391\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.005422\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.004481\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.007688\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.005959\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.004556\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.004974\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.004991\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.005923\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.004051\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.004402\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.004036\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.005718\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.003552\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.003977\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.003317\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.003503\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.004614\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.002491\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 9840/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.004210\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.003902\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.003792\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.003403\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.002724\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.002641\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.002946\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.002163\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.003091\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.003042\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.003988\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.003534\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.002342\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.002168\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.002705\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.003093\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.003009\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.001814\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.003400\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.002322\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.002052\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.001373\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.001464\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.002088\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.002378\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.002282\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.001576\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.002746\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.001666\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.002836\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 9898/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.001905\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.001984\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.001637\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.001635\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.001636\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.002227\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.001155\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.001913\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.001853\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.001580\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.001810\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.001530\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.001988\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.001291\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.002447\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.001340\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.002239\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.001878\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.001697\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.001517\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.000771\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.001120\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.001778\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.001183\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.002203\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.001007\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.001723\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.001209\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.001669\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.001333\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 9925/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.001697\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.001236\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.001641\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.001321\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.002535\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.001364\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.001507\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.002248\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.001686\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.001412\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.002113\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.000885\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.001600\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.000982\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.001520\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.000868\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.001987\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.002141\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.001976\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.001639\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.001102\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.001259\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.001296\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.001551\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.001234\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.000896\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.001266\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.001493\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.001374\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.001416\n",
      "\n",
      "Test set: Average loss: 0.0084, Accuracy: 9941/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.000754\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.001445\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.001112\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.001731\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.001216\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.001993\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.001152\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.000891\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.000622\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.001438\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.001028\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.001134\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.000628\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.001550\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.000656\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.001225\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.001094\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.001372\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.002405\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.001757\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.000826\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.001190\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.000676\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.001518\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.001601\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.001821\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.000962\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.000951\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.001598\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.002305\n",
      "\n",
      "Test set: Average loss: 0.0082, Accuracy: 9934/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.000951\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.001563\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.000972\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.001165\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.001340\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.000717\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.001412\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.001405\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.001319\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.001601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.001204\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.001131\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.001336\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.001258\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.000944\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.001601\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.000871\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.000581\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.001567\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.001672\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.000648\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.000897\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.001541\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.000899\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.001153\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.001129\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.000532\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.000738\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.000852\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.001289\n",
      "\n",
      "Test set: Average loss: 0.0101, Accuracy: 9921/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.001372\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.000904\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.001405\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.001744\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.000984\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.000958\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.001238\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.001211\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.001263\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.000457\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.000650\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.001055\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.001241\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.000661\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.001013\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.000811\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.001734\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.000949\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.000639\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.000798\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.000867\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.001242\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.000932\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.001336\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.001230\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.001206\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.001008\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.001344\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.000894\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.000727\n",
      "\n",
      "Test set: Average loss: 0.0092, Accuracy: 9929/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000842\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.001091\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.000720\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.001241\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.000985\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.001008\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.000713\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.001170\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.001337\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.000423\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.000985\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.000781\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.001019\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.001292\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.000630\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.000849\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.000536\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.000777\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.001438\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.001413\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.001210\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.001422\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.000976\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.000947\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.000604\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.000377\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.000207\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.000843\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.001115\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.001146\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 9919/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.002311\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.001263\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.000697\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.001122\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.000969\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.001029\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.000859\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.001056\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.000453\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.000738\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.001257\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.000754\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.000527\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.000521\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.000677\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.000682\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.000641\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.000613\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.001742\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.000696\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.000995\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.001033\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.001068\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.000826\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.001148\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.000846\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.000459\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.000699\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.000977\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.000622\n",
      "\n",
      "Test set: Average loss: 0.0076, Accuracy: 9935/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.000972\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 0.001135\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 0.000302\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 0.001119\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.000473\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.000764\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.000434\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 0.000844\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.001133\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 0.000674\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.001170\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 0.001028\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.001264\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 0.001307\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 0.000700\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.000756\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.000766\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 0.000549\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.000778\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 0.000802\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.000484\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 0.000876\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 0.000455\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 0.001149\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.001198\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.000930\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 0.000625\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 0.000286\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 0.001171\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 0.000735\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 9929/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.000920\n",
      "Train Epoch: 11 [2000/60000 (3%)]\tLoss: 0.000983\n",
      "Train Epoch: 11 [4000/60000 (7%)]\tLoss: 0.001782\n",
      "Train Epoch: 11 [6000/60000 (10%)]\tLoss: 0.001271\n",
      "Train Epoch: 11 [8000/60000 (13%)]\tLoss: 0.001019\n",
      "Train Epoch: 11 [10000/60000 (17%)]\tLoss: 0.001158\n",
      "Train Epoch: 11 [12000/60000 (20%)]\tLoss: 0.000664\n",
      "Train Epoch: 11 [14000/60000 (23%)]\tLoss: 0.000968\n",
      "Train Epoch: 11 [16000/60000 (27%)]\tLoss: 0.000658\n",
      "Train Epoch: 11 [18000/60000 (30%)]\tLoss: 0.000573\n",
      "Train Epoch: 11 [20000/60000 (33%)]\tLoss: 0.000451\n",
      "Train Epoch: 11 [22000/60000 (37%)]\tLoss: 0.001260\n",
      "Train Epoch: 11 [24000/60000 (40%)]\tLoss: 0.000807\n",
      "Train Epoch: 11 [26000/60000 (43%)]\tLoss: 0.000197\n",
      "Train Epoch: 11 [28000/60000 (47%)]\tLoss: 0.001224\n",
      "Train Epoch: 11 [30000/60000 (50%)]\tLoss: 0.000763\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.001939\n",
      "Train Epoch: 11 [34000/60000 (57%)]\tLoss: 0.000620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [36000/60000 (60%)]\tLoss: 0.001183\n",
      "Train Epoch: 11 [38000/60000 (63%)]\tLoss: 0.000534\n",
      "Train Epoch: 11 [40000/60000 (67%)]\tLoss: 0.000959\n",
      "Train Epoch: 11 [42000/60000 (70%)]\tLoss: 0.000295\n",
      "Train Epoch: 11 [44000/60000 (73%)]\tLoss: 0.000448\n",
      "Train Epoch: 11 [46000/60000 (77%)]\tLoss: 0.000817\n",
      "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.000437\n",
      "Train Epoch: 11 [50000/60000 (83%)]\tLoss: 0.000803\n",
      "Train Epoch: 11 [52000/60000 (87%)]\tLoss: 0.000652\n",
      "Train Epoch: 11 [54000/60000 (90%)]\tLoss: 0.000372\n",
      "Train Epoch: 11 [56000/60000 (93%)]\tLoss: 0.000698\n",
      "Train Epoch: 11 [58000/60000 (97%)]\tLoss: 0.000624\n",
      "\n",
      "Test set: Average loss: 0.0085, Accuracy: 9939/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.000600\n",
      "Train Epoch: 12 [2000/60000 (3%)]\tLoss: 0.000699\n",
      "Train Epoch: 12 [4000/60000 (7%)]\tLoss: 0.000934\n",
      "Train Epoch: 12 [6000/60000 (10%)]\tLoss: 0.000585\n",
      "Train Epoch: 12 [8000/60000 (13%)]\tLoss: 0.000593\n",
      "Train Epoch: 12 [10000/60000 (17%)]\tLoss: 0.001310\n",
      "Train Epoch: 12 [12000/60000 (20%)]\tLoss: 0.000580\n",
      "Train Epoch: 12 [14000/60000 (23%)]\tLoss: 0.000657\n",
      "Train Epoch: 12 [16000/60000 (27%)]\tLoss: 0.000553\n",
      "Train Epoch: 12 [18000/60000 (30%)]\tLoss: 0.000502\n",
      "Train Epoch: 12 [20000/60000 (33%)]\tLoss: 0.000658\n",
      "Train Epoch: 12 [22000/60000 (37%)]\tLoss: 0.000902\n",
      "Train Epoch: 12 [24000/60000 (40%)]\tLoss: 0.000574\n",
      "Train Epoch: 12 [26000/60000 (43%)]\tLoss: 0.001010\n",
      "Train Epoch: 12 [28000/60000 (47%)]\tLoss: 0.000818\n",
      "Train Epoch: 12 [30000/60000 (50%)]\tLoss: 0.001284\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.001195\n",
      "Train Epoch: 12 [34000/60000 (57%)]\tLoss: 0.001102\n",
      "Train Epoch: 12 [36000/60000 (60%)]\tLoss: 0.001424\n",
      "Train Epoch: 12 [38000/60000 (63%)]\tLoss: 0.000739\n",
      "Train Epoch: 12 [40000/60000 (67%)]\tLoss: 0.000624\n",
      "Train Epoch: 12 [42000/60000 (70%)]\tLoss: 0.000502\n",
      "Train Epoch: 12 [44000/60000 (73%)]\tLoss: 0.000920\n",
      "Train Epoch: 12 [46000/60000 (77%)]\tLoss: 0.000556\n",
      "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.000508\n",
      "Train Epoch: 12 [50000/60000 (83%)]\tLoss: 0.000520\n",
      "Train Epoch: 12 [52000/60000 (87%)]\tLoss: 0.001251\n",
      "Train Epoch: 12 [54000/60000 (90%)]\tLoss: 0.000487\n",
      "Train Epoch: 12 [56000/60000 (93%)]\tLoss: 0.000636\n",
      "Train Epoch: 12 [58000/60000 (97%)]\tLoss: 0.000996\n",
      "\n",
      "Test set: Average loss: 0.0069, Accuracy: 9937/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.000537\n",
      "Train Epoch: 13 [2000/60000 (3%)]\tLoss: 0.001072\n",
      "Train Epoch: 13 [4000/60000 (7%)]\tLoss: 0.000720\n",
      "Train Epoch: 13 [6000/60000 (10%)]\tLoss: 0.000683\n",
      "Train Epoch: 13 [8000/60000 (13%)]\tLoss: 0.000620\n",
      "Train Epoch: 13 [10000/60000 (17%)]\tLoss: 0.000855\n",
      "Train Epoch: 13 [12000/60000 (20%)]\tLoss: 0.000769\n",
      "Train Epoch: 13 [14000/60000 (23%)]\tLoss: 0.000697\n",
      "Train Epoch: 13 [16000/60000 (27%)]\tLoss: 0.000512\n",
      "Train Epoch: 13 [18000/60000 (30%)]\tLoss: 0.000441\n",
      "Train Epoch: 13 [20000/60000 (33%)]\tLoss: 0.000407\n",
      "Train Epoch: 13 [22000/60000 (37%)]\tLoss: 0.000497\n",
      "Train Epoch: 13 [24000/60000 (40%)]\tLoss: 0.000479\n",
      "Train Epoch: 13 [26000/60000 (43%)]\tLoss: 0.000807\n",
      "Train Epoch: 13 [28000/60000 (47%)]\tLoss: 0.000425\n",
      "Train Epoch: 13 [30000/60000 (50%)]\tLoss: 0.000890\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.000714\n",
      "Train Epoch: 13 [34000/60000 (57%)]\tLoss: 0.000357\n",
      "Train Epoch: 13 [36000/60000 (60%)]\tLoss: 0.000519\n",
      "Train Epoch: 13 [38000/60000 (63%)]\tLoss: 0.000506\n",
      "Train Epoch: 13 [40000/60000 (67%)]\tLoss: 0.000352\n",
      "Train Epoch: 13 [42000/60000 (70%)]\tLoss: 0.000304\n",
      "Train Epoch: 13 [44000/60000 (73%)]\tLoss: 0.000917\n",
      "Train Epoch: 13 [46000/60000 (77%)]\tLoss: 0.000709\n",
      "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.000808\n",
      "Train Epoch: 13 [50000/60000 (83%)]\tLoss: 0.001110\n",
      "Train Epoch: 13 [52000/60000 (87%)]\tLoss: 0.000523\n",
      "Train Epoch: 13 [54000/60000 (90%)]\tLoss: 0.000318\n",
      "Train Epoch: 13 [56000/60000 (93%)]\tLoss: 0.000695\n",
      "Train Epoch: 13 [58000/60000 (97%)]\tLoss: 0.000199\n",
      "\n",
      "Test set: Average loss: 0.0075, Accuracy: 9939/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.000677\n",
      "Train Epoch: 14 [2000/60000 (3%)]\tLoss: 0.000733\n",
      "Train Epoch: 14 [4000/60000 (7%)]\tLoss: 0.000699\n",
      "Train Epoch: 14 [6000/60000 (10%)]\tLoss: 0.001267\n",
      "Train Epoch: 14 [8000/60000 (13%)]\tLoss: 0.000354\n",
      "Train Epoch: 14 [10000/60000 (17%)]\tLoss: 0.000530\n",
      "Train Epoch: 14 [12000/60000 (20%)]\tLoss: 0.000435\n",
      "Train Epoch: 14 [14000/60000 (23%)]\tLoss: 0.000776\n",
      "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.000799\n",
      "Train Epoch: 14 [18000/60000 (30%)]\tLoss: 0.000373\n",
      "Train Epoch: 14 [20000/60000 (33%)]\tLoss: 0.000635\n",
      "Train Epoch: 14 [22000/60000 (37%)]\tLoss: 0.000386\n",
      "Train Epoch: 14 [24000/60000 (40%)]\tLoss: 0.000578\n",
      "Train Epoch: 14 [26000/60000 (43%)]\tLoss: 0.000640\n",
      "Train Epoch: 14 [28000/60000 (47%)]\tLoss: 0.000261\n",
      "Train Epoch: 14 [30000/60000 (50%)]\tLoss: 0.000492\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.000443\n",
      "Train Epoch: 14 [34000/60000 (57%)]\tLoss: 0.001105\n",
      "Train Epoch: 14 [36000/60000 (60%)]\tLoss: 0.000561\n",
      "Train Epoch: 14 [38000/60000 (63%)]\tLoss: 0.000644\n",
      "Train Epoch: 14 [40000/60000 (67%)]\tLoss: 0.000656\n",
      "Train Epoch: 14 [42000/60000 (70%)]\tLoss: 0.000975\n",
      "Train Epoch: 14 [44000/60000 (73%)]\tLoss: 0.000459\n",
      "Train Epoch: 14 [46000/60000 (77%)]\tLoss: 0.000648\n",
      "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.000761\n",
      "Train Epoch: 14 [50000/60000 (83%)]\tLoss: 0.000817\n",
      "Train Epoch: 14 [52000/60000 (87%)]\tLoss: 0.001450\n",
      "Train Epoch: 14 [54000/60000 (90%)]\tLoss: 0.000513\n",
      "Train Epoch: 14 [56000/60000 (93%)]\tLoss: 0.000795\n",
      "Train Epoch: 14 [58000/60000 (97%)]\tLoss: 0.000737\n",
      "\n",
      "Test set: Average loss: 0.0073, Accuracy: 9925/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.000625\n",
      "Train Epoch: 15 [2000/60000 (3%)]\tLoss: 0.000461\n",
      "Train Epoch: 15 [4000/60000 (7%)]\tLoss: 0.001439\n",
      "Train Epoch: 15 [6000/60000 (10%)]\tLoss: 0.000736\n",
      "Train Epoch: 15 [8000/60000 (13%)]\tLoss: 0.000371\n",
      "Train Epoch: 15 [10000/60000 (17%)]\tLoss: 0.001203\n",
      "Train Epoch: 15 [12000/60000 (20%)]\tLoss: 0.000364\n",
      "Train Epoch: 15 [14000/60000 (23%)]\tLoss: 0.000359\n",
      "Train Epoch: 15 [16000/60000 (27%)]\tLoss: 0.000377\n",
      "Train Epoch: 15 [18000/60000 (30%)]\tLoss: 0.000349\n",
      "Train Epoch: 15 [20000/60000 (33%)]\tLoss: 0.000500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-26f55a153f4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Call training functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-e16bbd116b29>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-ff05e569b558>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, lengths, targets, size_average)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Call training functions \n",
    "Loss = [], L_every = 1\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(epoch,Loss,L_every)\n",
    "    test_loss = test()\n",
    "    scheduler.step(test_loss)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network classes\n",
    "#capsnet = CapsNet(3, 10)\n",
    "#reconstructionnet = ReconstructionNet(16, 10)\n",
    "#model = CapsNetWithReconstruction(capsnet, reconstructionnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
